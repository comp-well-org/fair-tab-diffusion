{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tomli\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datavis import METHOD_MAPPER, DATASET_MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PATH = './eval/'\n",
    "RESULTS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path) -> dict:\n",
    "    with open(path, 'rb') as f:\n",
    "        return tomli.load(f)\n",
    "    \n",
    "def load_json(js_path) -> dict:\n",
    "    with open(js_path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codi', 'fairsmote', 'fairtabddpm', 'fairtabgan', 'goggle', 'great', 'smote', 'stasy', 'tabddpm', 'tabsyn']\n"
     ]
    }
   ],
   "source": [
    "def print_config():\n",
    "    config = load_config('assess.toml')\n",
    "    considered = config['methods']['considered']\n",
    "    RESULTS['methods'] = considered\n",
    "    print(considered)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_score(dataset, stats=False):\n",
    "    score_path = os.path.join(EVAL_PATH, 'quality', dataset, 'score.json')\n",
    "    dcr_path = os.path.join(EVAL_PATH, 'quality', dataset, 'dcr.json')\n",
    "\n",
    "    score = load_json(score_path)\n",
    "    dcr = load_json(dcr_path)\n",
    "    for data in score:\n",
    "        score[data]['dcr'] = dcr[data]\n",
    "    \n",
    "    score_stats = {}\n",
    "    if stats:\n",
    "        for data in score:\n",
    "            score_stats[data] = {}\n",
    "            for metric in score[data]:\n",
    "                if metric not in score_stats:\n",
    "                    mu, sigma = np.mean(score[data][metric]), np.std(score[data][metric])\n",
    "                    mu, sigma = round(mu, 3), round(sigma, 3)\n",
    "                    score_stats[data][metric] = (mu, sigma)\n",
    "        return score_stats\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tuple(t):\n",
    "    ans = (1 - t[0], t[1])\n",
    "    ans = (round(ans[0], 3), round(ans[1], 3))\n",
    "    return ans\n",
    "\n",
    "def convert_to_latex(t):    \n",
    "    ans = f\"${t[0]:.3f}_{{\\pm {t[1]:.3f}}}$\"\n",
    "    # eliminate the leading zero\n",
    "    ans = ans.replace('0.', '.')\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tex_score_df_dataset(dataset, idx_order):\n",
    "    score = read_score(dataset, stats=True)\n",
    "    # metrics = ['shape', 'trend', 'dcr']\n",
    "    metrics = ['shape', 'trend']\n",
    "    score_df = pd.DataFrame(score).T[metrics]\n",
    "\n",
    "    # rename the columns\n",
    "    ds_name = DATASET_MAPPER[dataset]\n",
    "    score_df = score_df.rename(columns={\n",
    "        'shape': f'{ds_name} - Density',\n",
    "        'trend': f'{ds_name} - Correlation',\n",
    "    })\n",
    "\n",
    "    # rearrange the index order\n",
    "    score_df = score_df.reindex(idx_order)\n",
    "\n",
    "    # rename index according to the method mapper\n",
    "    score_df = score_df.rename(index=METHOD_MAPPER)\n",
    "\n",
    "    # convert the tuple to latex\n",
    "    score_df = score_df.map(convert_tuple).map(convert_to_latex)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_order = [\n",
    "    'codi', 'goggle', 'great', 'smote', 'stasy',\n",
    "    'tabddpm', 'tabsyn', 'fairsmote', 'fairtabgan', 'fairtabddpm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = get_tex_score_df_dataset('adult', idx_order)\n",
    "compas_df = get_tex_score_df_dataset('compass', idx_order)\n",
    "bank_df = get_tex_score_df_dataset('bank', idx_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult - Density</th>\n",
       "      <th>Bank - Density</th>\n",
       "      <th>COMPAS - Density</th>\n",
       "      <th>Ave. - Density</th>\n",
       "      <th>Adult - Correlation</th>\n",
       "      <th>Bank - Correlation</th>\n",
       "      <th>COMPAS - Correlation</th>\n",
       "      <th>Ave. - Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CoDi</th>\n",
       "      <td>$.145_{\\pm .000}$</td>\n",
       "      <td>$.154_{\\pm .000}$</td>\n",
       "      <td>$.205_{\\pm .001}$</td>\n",
       "      <td>$16.8\\%$</td>\n",
       "      <td>$.495_{\\pm .000}$</td>\n",
       "      <td>$.344_{\\pm .001}$</td>\n",
       "      <td>$.550_{\\pm .001}$</td>\n",
       "      <td>$46.3\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goggle</th>\n",
       "      <td>$.158_{\\pm .001}$</td>\n",
       "      <td>$.131_{\\pm .000}$</td>\n",
       "      <td>$.164_{\\pm .001}$</td>\n",
       "      <td>$15.1\\%$</td>\n",
       "      <td>$.447_{\\pm .016}$</td>\n",
       "      <td>$.232_{\\pm .000}$</td>\n",
       "      <td>$.332_{\\pm .022}$</td>\n",
       "      <td>$33.7\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Adult - Density     Bank - Density   COMPAS - Density  \\\n",
       "CoDi    $.145_{\\pm .000}$  $.154_{\\pm .000}$  $.205_{\\pm .001}$   \n",
       "Goggle  $.158_{\\pm .001}$  $.131_{\\pm .000}$  $.164_{\\pm .001}$   \n",
       "\n",
       "       Ave. - Density Adult - Correlation Bank - Correlation  \\\n",
       "CoDi         $16.8\\%$   $.495_{\\pm .000}$  $.344_{\\pm .001}$   \n",
       "Goggle       $15.1\\%$   $.447_{\\pm .016}$  $.232_{\\pm .000}$   \n",
       "\n",
       "       COMPAS - Correlation Ave. - Correlation  \n",
       "CoDi      $.550_{\\pm .001}$           $46.3\\%$  \n",
       "Goggle    $.332_{\\pm .022}$           $33.7\\%$  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([adult_df, compas_df, bank_df], axis=1)\n",
    "density_cols = [col for col in all_df.columns if 'Density' in col]\n",
    "correlation_cols = [col for col in all_df.columns if 'Correlation' in col]\n",
    "all_df['Ave. - Density'] = all_df[density_cols].apply(lambda x: np.mean([float(i.split('_')[0][1:]) for i in x]), axis=1)\n",
    "all_df['Ave. - Correlation'] = all_df[correlation_cols].apply(lambda x: np.mean([float(i.split('_')[0][1:]) for i in x]), axis=1)\n",
    "\n",
    "# to percentage\n",
    "all_df['Ave. - Density'] = all_df['Ave. - Density'].map(lambda x: x * 100)\n",
    "all_df['Ave. - Correlation'] = all_df['Ave. - Correlation'].map(lambda x: x * 100)\n",
    "\n",
    "all_df['Ave. - Density'] = all_df['Ave. - Density'].map(lambda x: f\"${x:.1f}\\%$\")\n",
    "all_df['Ave. - Correlation'] = all_df['Ave. - Correlation'].map(lambda x: f\"${x:.1f}\\%$\")\n",
    "\n",
    "# reorder the columns\n",
    "all_df = all_df[\n",
    "    [\n",
    "        'Adult - Density', 'Bank - Density', 'COMPAS - Density', 'Ave. - Density',\n",
    "        'Adult - Correlation', 'Bank - Correlation', 'COMPAS - Correlation', 'Ave. - Correlation',\n",
    "    ]\n",
    "]\n",
    "all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoDi     & $.145_{\\pm .000}$ & $.154_{\\pm .000}$ & $.205_{\\pm .001}$ & $16.8\\%$ & $.495_{\\pm .000}$ & $.344_{\\pm .001}$ & $.550_{\\pm .001}$ & $46.3\\%$ \\\\\n",
      "Goggle   & $.158_{\\pm .001}$ & $.131_{\\pm .000}$ & $.164_{\\pm .001}$ & $15.1\\%$ & $.447_{\\pm .016}$ & $.232_{\\pm .000}$ & $.332_{\\pm .022}$ & $33.7\\%$ \\\\\n",
      "GReaT    & $.077_{\\pm .000}$ & $.102_{\\pm .001}$ & $.093_{\\pm .001}$ & $9.1\\%$ & $.208_{\\pm .015}$ & $.213_{\\pm .010}$ & $.165_{\\pm .016}$ & $19.5\\%$ \\\\\n",
      "SMOTE    & $.025_{\\pm .000}$ & $.020_{\\pm .000}$ & $.021_{\\pm .001}$ & $2.2\\%$ & $.054_{\\pm .004}$ & $.042_{\\pm .005}$ & $.047_{\\pm .005}$ & $4.8\\%$ \\\\\n",
      "STaSy    & $.102_{\\pm .000}$ & $.182_{\\pm .000}$ & $.108_{\\pm .001}$ & $13.1\\%$ & $.163_{\\pm .000}$ & $.221_{\\pm .001}$ & $.138_{\\pm .001}$ & $17.4\\%$ \\\\\n",
      "TabDDPM  & $.037_{\\pm .001}$ & $.028_{\\pm .001}$ & $.057_{\\pm .001}$ & $4.1\\%$ & $.055_{\\pm .001}$ & $.052_{\\pm .001}$ & $.090_{\\pm .001}$ & $6.6\\%$ \\\\\n",
      "TabSyn   & $.010_{\\pm .000}$ & $.009_{\\pm .000}$ & $.027_{\\pm .001}$ & $1.5\\%$ & $.035_{\\pm .001}$ & $.033_{\\pm .002}$ & $.054_{\\pm .001}$ & $4.1\\%$ \\\\\n",
      "FairCB   & $.076_{\\pm .000}$ & $.066_{\\pm .000}$ & $.039_{\\pm .000}$ & $6.0\\%$ & $.125_{\\pm .000}$ & $.111_{\\pm .000}$ & $.074_{\\pm .000}$ & $10.3\\%$ \\\\\n",
      "FairTGAN & $.034_{\\pm .000}$ & $.030_{\\pm .000}$ & $.055_{\\pm .001}$ & $4.0\\%$ & $.080_{\\pm .001}$ & $.053_{\\pm .000}$ & $.087_{\\pm .001}$ & $7.3\\%$ \\\\\n",
      "Ours     & $.126_{\\pm .001}$ & $.121_{\\pm .000}$ & $.109_{\\pm .001}$ & $11.9\\%$ & $.201_{\\pm .000}$ & $.174_{\\pm .005}$ & $.174_{\\pm .003}$ & $18.3\\%$ \\\\\n"
     ]
    }
   ],
   "source": [
    "methods = all_df.index\n",
    "max_str_len = max([len(m) for m in methods])\n",
    "\n",
    "for i in range(all_df.shape[0]):\n",
    "    method = all_df.index[i]\n",
    "    n_slash = max_str_len - len(method)\n",
    "    print(\n",
    "        method + ' ' * n_slash, '&',\n",
    "        all_df.iloc[i].values[0], '&',\n",
    "        all_df.iloc[i].values[1], '&',\n",
    "        all_df.iloc[i].values[2], '&',\n",
    "        all_df.iloc[i].values[3], '&',\n",
    "        all_df.iloc[i].values[4], '&',\n",
    "        all_df.iloc[i].values[5], '&',\n",
    "        all_df.iloc[i].values[6], '&',\n",
    "        all_df.iloc[i].values[7], '\\\\\\\\',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_auc(dataset, method, mode='original', stats=False):\n",
    "    js_path = os.path.join(EVAL_PATH, 'learning', dataset, f'best_{mode}_{method}.json')\n",
    "    scores = {}\n",
    "    ans = load_json(js_path)['CatBoost']\n",
    "    for key in ans:\n",
    "        scores[key] = ans[key]['Test']\n",
    "    scores = scores['AUC']\n",
    "    \n",
    "    if stats:\n",
    "        mu, sigma = np.mean(scores), np.std(scores)\n",
    "        mu, sigma = round(mu, 3), round(sigma, 3)\n",
    "        return (mu, sigma)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_auc(mode='original'):\n",
    "    datasets = ['adult', 'bank', 'compass']\n",
    "    methods = RESULTS['methods'] + ['real']\n",
    "    auc_scores = {}\n",
    "    for dataset in datasets:\n",
    "        auc_scores[dataset] = {}\n",
    "        for method in methods:\n",
    "            auc = read_auc(dataset, method, mode=mode, stats=True)\n",
    "            auc_scores[dataset][method] = auc\n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latex_percentage(num):\n",
    "    # input is a float\n",
    "    return f\"${num:.1f}\\%$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real     & $.928_{\\pm .000}$ & $.936_{\\pm .000}$ & $.810_{\\pm .001}$ & $89.1\\%$ \\\\\n",
      "CoDi     & $.858_{\\pm .001}$ & $.826_{\\pm .014}$ & $.678_{\\pm .002}$ & $78.7\\%$ \\\\\n",
      "Goggle   & $.740_{\\pm .002}$ & $.737_{\\pm .006}$ & $.650_{\\pm .009}$ & $70.9\\%$ \\\\\n",
      "GReaT    & $.901_{\\pm .002}$ & $.688_{\\pm .024}$ & $.717_{\\pm .008}$ & $76.9\\%$ \\\\\n",
      "SMOTE    & $.914_{\\pm .000}$ & $.928_{\\pm .001}$ & $.778_{\\pm .002}$ & $87.3\\%$ \\\\\n",
      "STaSy    & $.885_{\\pm .003}$ & $.895_{\\pm .003}$ & $.728_{\\pm .013}$ & $83.6\\%$ \\\\\n",
      "TabDDPM  & $.907_{\\pm .001}$ & $.917_{\\pm .002}$ & $.745_{\\pm .001}$ & $85.6\\%$ \\\\\n",
      "TabSyn   & $.911_{\\pm .000}$ & $.919_{\\pm .000}$ & $.749_{\\pm .001}$ & $86.0\\%$ \\\\\n",
      "FairCB   & $.915_{\\pm .001}$ & $.907_{\\pm .002}$ & $.771_{\\pm .001}$ & $86.4\\%$ \\\\\n",
      "FairTGAN & $.881_{\\pm .000}$ & $.863_{\\pm .006}$ & $.705_{\\pm .002}$ & $81.6\\%$ \\\\\n",
      "Ours     & $.893_{\\pm .002}$ & $.914_{\\pm .002}$ & $.734_{\\pm .001}$ & $84.7\\%$ \\\\\n"
     ]
    }
   ],
   "source": [
    "auc_df = pd.DataFrame(read_all_auc())\n",
    "# average the first elment of the tuple in the dataframe\n",
    "auc_df['average'] = auc_df.apply(lambda x: np.mean([i[0] for i in x.values]), axis=1)\n",
    "\n",
    "# convert to latex for adult, bank, and compass\n",
    "for dataset in ['adult', 'bank', 'compass']:\n",
    "    for method in RESULTS['methods']:\n",
    "        auc_df[dataset][method] = convert_to_latex(auc_df[dataset][method])\n",
    "    auc_df[dataset]['real'] = convert_to_latex(auc_df[dataset]['real'])\n",
    "\n",
    "# transform the average to differnce with real as the baseline\n",
    "# auc_df['average'] = (auc_df['average'] - auc_df['average']['real']) / auc_df['average']['real']\n",
    "\n",
    "# convert average to percentage and then to latex\n",
    "auc_df['average'] = auc_df['average'] * 100 \n",
    "\n",
    "# convert to latex\n",
    "auc_df['average'] = auc_df['average'].map(to_latex_percentage)\n",
    "\n",
    "# rename the columns\n",
    "auc_df = auc_df.rename(columns={\n",
    "    'average': 'Average',\n",
    "    'adult': 'Adult',\n",
    "    'bank': 'Bank',\n",
    "    'compass': 'COMPAS',\n",
    "})\n",
    "\n",
    "# reorder the index\n",
    "auc_df = auc_df.reindex(['real'] + idx_order)\n",
    "\n",
    "# rename the index\n",
    "auc_df = auc_df.rename(index=METHOD_MAPPER)\n",
    "\n",
    "methods = auc_df.index\n",
    "max_str_len = max([len(m) for m in methods])\n",
    "\n",
    "for i in range(auc_df.shape[0]):\n",
    "    method = auc_df.index[i]\n",
    "    n_slash = max_str_len - len(method)\n",
    "    print(\n",
    "        method + ' ' * n_slash, '&',\n",
    "        auc_df.iloc[i].values[0], '&',\n",
    "        auc_df.iloc[i].values[1], '&',\n",
    "        auc_df.iloc[i].values[2], '&',\n",
    "        auc_df.iloc[i].values[3], '\\\\\\\\',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fair(dataset, method, mode='original', metric='DPR', stats=False):\n",
    "    js_path = os.path.join(EVAL_PATH, 'learning', dataset, f'best_{mode}_{method}.json')\n",
    "    scores = {}\n",
    "    ans = load_json(js_path)['CatBoost']\n",
    "    for key in ans:\n",
    "        scores[key] = ans[key]['Test']\n",
    "    \n",
    "    if dataset == 'adult' or dataset == 'compass':\n",
    "        attri = 'sex'\n",
    "    elif dataset == 'bank':\n",
    "        attri = 'age-group'\n",
    "        \n",
    "    scores = scores[metric][attri]\n",
    "    \n",
    "    if stats:\n",
    "        mu, sigma = np.mean(scores), np.std(scores)\n",
    "        mu, sigma = round(mu, 3), round(sigma, 3)\n",
    "        return (mu, sigma)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real     & $.309_{\\pm .001}$ & $.402_{\\pm .015}$ & $.675_{\\pm .006}$ & $46.2\\%$ & $.193_{\\pm .005}$ & $.367_{\\pm .024}$ & $.645_{\\pm .015}$ & $40.2\\%$ \\\\\n",
      "CoDi     & $.293_{\\pm .034}$ & $.189_{\\pm .054}$ & $.855_{\\pm .025}$ & $44.6\\%$ & $.247_{\\pm .042}$ & $.172_{\\pm .063}$ & $.857_{\\pm .031}$ & $42.5\\%$ \\\\\n",
      "Goggle   & $.833_{\\pm .030}$ & $.533_{\\pm .016}$ & $.827_{\\pm .070}$ & $73.1\\%$ & $.882_{\\pm .023}$ & $.542_{\\pm .024}$ & $.807_{\\pm .053}$ & $74.4\\%$ \\\\\n",
      "GReaT    & $.249_{\\pm .015}$ & $.572_{\\pm .289}$ & $.624_{\\pm .066}$ & $48.2\\%$ & $.155_{\\pm .028}$ & $.380_{\\pm .126}$ & $.543_{\\pm .075}$ & $35.9\\%$ \\\\\n",
      "SMOTE    & $.321_{\\pm .006}$ & $.405_{\\pm .028}$ & $.648_{\\pm .021}$ & $45.8\\%$ & $.254_{\\pm .011}$ & $.381_{\\pm .026}$ & $.589_{\\pm .009}$ & $40.8\\%$ \\\\\n",
      "STaSy    & $.261_{\\pm .045}$ & $.468_{\\pm .123}$ & $.436_{\\pm .092}$ & $38.8\\%$ & $.182_{\\pm .069}$ & $.451_{\\pm .113}$ & $.433_{\\pm .140}$ & $35.5\\%$ \\\\\n",
      "TabDDPM  & $.261_{\\pm .006}$ & $.337_{\\pm .020}$ & $.558_{\\pm .041}$ & $38.5\\%$ & $.156_{\\pm .007}$ & $.334_{\\pm .028}$ & $.540_{\\pm .047}$ & $34.3\\%$ \\\\\n",
      "TabSyn   & $.281_{\\pm .017}$ & $.336_{\\pm .016}$ & $.697_{\\pm .040}$ & $43.8\\%$ & $.178_{\\pm .019}$ & $.317_{\\pm .023}$ & $.664_{\\pm .062}$ & $38.6\\%$ \\\\\n",
      "FairCB   & $.286_{\\pm .002}$ & $.719_{\\pm .005}$ & $.675_{\\pm .006}$ & $56.0\\%$ & $.192_{\\pm .003}$ & $.801_{\\pm .016}$ & $.638_{\\pm .021}$ & $54.4\\%$ \\\\\n",
      "FairTGAN & $.554_{\\pm .006}$ & $.338_{\\pm .093}$ & $.448_{\\pm .025}$ & $44.7\\%$ & $.697_{\\pm .017}$ & $.158_{\\pm .033}$ & $.392_{\\pm .041}$ & $41.6\\%$ \\\\\n",
      "Ours     & $.543_{\\pm .026}$ & $.710_{\\pm .057}$ & $.800_{\\pm .080}$ & $68.4\\%$ & $.667_{\\pm .059}$ & $.649_{\\pm .040}$ & $.825_{\\pm .113}$ & $71.4\\%$ \\\\\n"
     ]
    }
   ],
   "source": [
    "dpr_dict = {}\n",
    "for dataset in ['adult', 'bank', 'compass']:\n",
    "    dpr_dict[dataset] = {}\n",
    "    for method in ['real'] + RESULTS['methods']:\n",
    "        dpr = read_fair(dataset, method, metric='DPR', stats=True)\n",
    "        dpr_dict[dataset][method] = dpr\n",
    "\n",
    "dpr_df = pd.DataFrame(dpr_dict)\n",
    "dpr_df['average'] = dpr_df.apply(lambda x: np.mean([i[0] for i in x.values]), axis=1)\n",
    "\n",
    "# convert to latex for adult, bank, and compass\n",
    "for dataset in ['adult', 'bank', 'compass']:\n",
    "    for method in RESULTS['methods']:\n",
    "        dpr_df[dataset][method] = convert_to_latex(dpr_df[dataset][method])\n",
    "    dpr_df[dataset]['real'] = convert_to_latex(dpr_df[dataset]['real'])\n",
    "\n",
    "dpr_df['average'] = dpr_df['average'] * 100 \n",
    "dpr_df['average'] = dpr_df['average'].map(to_latex_percentage)\n",
    "\n",
    "eor_dict = {}\n",
    "for dataset in ['adult', 'bank', 'compass']:\n",
    "    eor_dict[dataset] = {}\n",
    "    for method in ['real'] + RESULTS['methods']:\n",
    "        eor = read_fair(dataset, method, metric='EOR', stats=True)\n",
    "        eor_dict[dataset][method] = eor\n",
    "        \n",
    "eor_df = pd.DataFrame(eor_dict)\n",
    "eor_df['average'] = eor_df.apply(lambda x: np.mean([i[0] for i in x.values]), axis=1)\n",
    "\n",
    "# convert to latex for adult, bank, and compass\n",
    "for dataset in ['adult', 'bank', 'compass']:\n",
    "    for method in RESULTS['methods']:\n",
    "        eor_df[dataset][method] = convert_to_latex(eor_df[dataset][method])\n",
    "    eor_df[dataset]['real'] = convert_to_latex(eor_df[dataset]['real'])\n",
    "\n",
    "eor_df['average'] = eor_df['average'] * 100\n",
    "eor_df['average'] = eor_df['average'].map(to_latex_percentage)\n",
    "\n",
    "# reorder the index\n",
    "dpr_df = dpr_df.reindex(['real'] + idx_order)\n",
    "eor_df = eor_df.reindex(['real'] + idx_order)\n",
    "\n",
    "# rename the index\n",
    "dpr_df = dpr_df.rename(index=METHOD_MAPPER)\n",
    "eor_df = eor_df.rename(index=METHOD_MAPPER)\n",
    "\n",
    "fair_df = pd.concat([dpr_df, eor_df], axis=1)\n",
    "\n",
    "for i in range(fair_df.shape[0]):\n",
    "    method = fair_df.index[i]\n",
    "    n_slash = max_str_len - len(method)\n",
    "    print(\n",
    "        method + ' ' * n_slash, '&',\n",
    "        fair_df.iloc[i].values[0], '&',\n",
    "        fair_df.iloc[i].values[1], '&',\n",
    "        fair_df.iloc[i].values[2], '&',\n",
    "        fair_df.iloc[i].values[3], '&',\n",
    "        fair_df.iloc[i].values[4], '&',\n",
    "        fair_df.iloc[i].values[5], '&',\n",
    "        fair_df.iloc[i].values[6], '&',\n",
    "        fair_df.iloc[i].values[7], '\\\\\\\\',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
